{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold, LeaveOneOut,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données\n",
    "palu=pd.read_excel('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\palu_impute001.xlsx')\n",
    "# Chargement du jeu de données\n",
    "palu1=pd.read_excel('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\MORBIDITE.xls')\n",
    "\n",
    "\n",
    "# Selection des features du paludisme\n",
    "paluu=pd.DataFrame(palu, columns = [  'TEMPERATURE','S_M8_APPETIT', 'S_FATIGUE', 'S_ARTHRALGI',\n",
    "                                    'S_T_DIGESTIF', 'S_VERTIGE', 'S_FRISSON', 'S_MYALGIE', 'S_DABDO', \n",
    "                                    'S_VOMISS', 'S_NAUSEE', 'S_CEPHALE', 'S_FIEVRE','Diagnostic'])\n",
    "\n",
    "\n",
    "# Selection des features du paludisme\n",
    "paluu1=pd.DataFrame(palu1, columns = [ 'TEMPERATURE', 'S_M8_APPETIT', 'S_FATIGUE', 'S_ARTHRALGI',\n",
    "                                    'S_T_DIGESTIF', 'S_VERTIGE', 'S_FRISSON', 'S_MYALGIE', 'S_DABDO', \n",
    "                                    'S_VOMISS', 'S_NAUSEE', 'S_CEPHALE', 'S_FIEVRE','Diagnostic'])\n",
    "\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "\n",
    "\n",
    "\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "\n",
    "\n",
    "palu2=paluu.append(paluu1)\n",
    "\n",
    "# Selection des features du paludisme\n",
    "X=palu2.iloc[:,0:13]       \n",
    "\n",
    "#X=pd.DataFrame(palu2, columns = [  'TEMPERATURE', 'S_M8_APPETIT', 'S_FATIGUE', 'S_ARTHRALGI',\n",
    "                                    #'S_T_DIGESTIF', 'S_VERTIGE', 'S_FRISSON', 'S_MYALGIE', 'S_DABDO', \n",
    "                                    #'S_VOMISS', 'S_NAUSEE', 'S_CEPHALE', 'S_FIEVRE'])\n",
    "y = palu2['Diagnostic']\n",
    "X1_train, MX_test, y1_train, My_test = train_test_split(X, y,test_size=0.2 ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les differentes methodes pour faire une validation croisée(Cross Validation)\n",
    "cv=KFold(5,random_state=0)\n",
    "cv1= LeaveOneOut()\n",
    "cv2=StratifiedKFold(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.8073638197713517\n",
      "best score {'criterion': 'gini', 'max_depth': 17}\n",
      "best score 0.8086079354404841\n",
      "best score 0.7953934095494285\n",
      "best score {'max_iter': 500, 'solver': 'lbfgs'}\n",
      "best score 0.795965030262273\n",
      "best score 0.7978143913920646\n",
      "best score {'var_smoothing': 0.1}\n",
      "best score 0.7983860121049092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Chercher les meilleurs paramètres du modele\n",
    "param_grid={'max_depth': np.arange(12,20), 'criterion':['gini','entropy']}\n",
    "grid=GridSearchCV( DecisionTreeClassifier(),param_grid, cv=cv2)\n",
    "grid.fit(X1_train,y1_train)\n",
    "\n",
    "#Afficher le meilleur score\n",
    "print('best score',grid.best_score_)\n",
    "# Afficher les meilleurs parametres\n",
    "print('best score',grid.best_params_)\n",
    "# Recuperer le meilleur modele fourni \n",
    "model=grid.best_estimator_\n",
    "print('best score',model.score(MX_test,My_test))\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rf= LogisticRegression()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid={'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],'max_iter':[10, 100,500,1000, 2000, 3000,4000]}\n",
    "grid2=GridSearchCV( LogisticRegression(),param_grid, cv=StratifiedKFold(5)  )\n",
    "grid2.fit(X1_train,y1_train)\n",
    "print('best score',grid2.best_score_)\n",
    "print('best score',grid2.best_params_)\n",
    "model2=grid2.best_estimator_\n",
    "print('best score',model2.score(MX_test,My_test))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "param_grid={'var_smoothing': np.linspace(0.1,1,10)}\n",
    "grid3=GridSearchCV( GaussianNB(),param_grid, cv=StratifiedKFold(5)  )\n",
    "grid3.fit(X1_train,y1_train)\n",
    "\n",
    "\n",
    "print('best score',grid3.best_score_)\n",
    "print('best score',grid3.best_params_)\n",
    "model3=grid3.best_estimator_\n",
    "print('best score',model3.score(MX_test,My_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max voting method is generally used for classification problems. In this technique, multiple models are used to make \n",
    "\n",
    "predictions for each data point. The predictions by each model are considered as a ‘vote’. The predictions which we get\n",
    "\n",
    "from the majority of the models are used as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7982515131136516\n",
      "[[4809  689]\n",
      " [ 811 1126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      5498\n",
      "           1       0.62      0.58      0.60      1937\n",
      "\n",
      "    accuracy                           0.80      7435\n",
      "   macro avg       0.74      0.73      0.73      7435\n",
      "weighted avg       0.79      0.80      0.80      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model = VotingClassifier(estimators=[('dt', model1), ('lr', model2),('nb',model3)], voting='hard')\n",
    "model.fit(X1_train,y1_train)\n",
    "print(model.score(MX_test,My_test))\n",
    "\n",
    "y_pred=model.predict(MX_test)\n",
    "#print(model.score(y_pred,My_test))\n",
    "print(confusion_matrix(My_test, y_pred))  \n",
    "print(classification_report(My_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the max voting technique, multiple predictions are made for each data point in averaging. In \n",
    "this method, we take an average of predictions from all the models and use it to make the final prediction. \n",
    "Averaging can be used for making predictions in regression problems or while calculating probabilities for\n",
    "classification problems.\n",
    "\n",
    "For example, in the below case, the averaging method would take the average of all the values.\n",
    "\n",
    "i.e. (5+4+5+4+4)/5 = 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8073974445191661"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = DecisionTreeClassifier(random_state=1)\n",
    "model3=GaussianNB()\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('nb',model3)], voting='hard')\n",
    "model.fit(X1_train,y1_train)\n",
    "model.score(MX_test,My_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025554808338937"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VotingClassifier(estimators=[('dt', model1), ('lr', model2),('nb',model3)], voting='hard')\n",
    "model.fit(X1_train,y1_train)\n",
    "model.score(MX_test,My_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(MX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4588  910]\n",
      " [ 522 1415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87      5498\n",
      "           1       0.61      0.73      0.66      1937\n",
      "\n",
      "    accuracy                           0.81      7435\n",
      "   macro avg       0.75      0.78      0.76      7435\n",
      "weighted avg       0.82      0.81      0.81      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(My_test, y_pred))  \n",
    "print(classification_report(My_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
