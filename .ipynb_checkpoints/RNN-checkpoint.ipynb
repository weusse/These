{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import get_prices as hist\n",
    "import tensorflow as tf\n",
    "#from preprocessing import DataProcessing\n",
    "import pandas_datareader.data as pdr\n",
    "#import fix_yahoo_finance as fix\n",
    "#fix.pdr_override()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "palu=pd.read_excel('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\palu_impute001.xlsx')\n",
    "paluu=pd.DataFrame(palu, columns = ['PPOIDS', 'TEMPERATURE', 'S_M8_APPETIT', 'S_FATIGUE', 'S_ARTHRALGI',\n",
    "                                    'S_T_DIGESTIF', 'S_VERTIGE', 'S_FRISSON', 'S_MYALGIE', 'S_DABDO', \n",
    "                                    'S_VOMISS', 'S_NAUSEE', 'S_CEPHALE', 'S_FIEVRE','TDR'])\n",
    "\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "X = paluu\n",
    "y = palu['Diagnostic']\n",
    "X1_train, MX_test, y1_train, My_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#Suréchantillonnage avec l'algorithme SMOTE\n",
    "X1 = paluu\n",
    "y1 =palu['Diagnostic']\n",
    "y1= pd.DataFrame(y1)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "Re= SMOTE(random_state=0)\n",
    "#X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)\n",
    "#columns = X1_train.columns\n",
    "Re_data_X1,Re_data_y1=Re.fit_sample(X1_train, y1_train)\n",
    "Re_data_X1 = pd.DataFrame(data=Re_data_X1 )\n",
    "# Nous séparons notre jeu données palu en deux parties. Une partie pour entrainer X_train et un partie pour tester X_test\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "X_train =Re_data_X1\n",
    "y_train=Re_data_y1\n",
    "#y_train= pd.DataFrame(Re_data_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-63f871238906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3379\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_train\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = process.X_train.reshape((3379, 10, 1)) / 200\n",
    "Y_train = process.Y_train / 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train = process.X_train.reshape((3379, 10, 1)) / 200\n",
    "Y_train = process.Y_train / 200\n",
    "\n",
    "X_test = process.X_test.reshape(359, 10, 1) / 200\n",
    "Y_test = process.Y_test / 200\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(20, input_shape=(10, 1), return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(20))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.relu))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50)\n",
    "\n",
    "print(model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train(self, seq_len):\n",
    "    \"\"\"\n",
    "    Generates training data\n",
    "    :param seq_len: length of window\n",
    "    :return: X_train and Y_train\n",
    "    \"\"\"\n",
    "    for i in range((len(self.stock_train)//seq_len)*seq_len - seq_len - 1):\n",
    "        x = np.array(self.stock_train.iloc[i: i + seq_len, 1])\n",
    "        y = np.array([self.stock_train.iloc[i + seq_len + 1, 1]], np.float64)\n",
    "        self.input_train.append(x)\n",
    "        self.output_train.append(y)\n",
    "    self.X_train = np.array(self.input_train)\n",
    "    self.Y_train = np.array(self.output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: inputs=         0   1  2  3  4  5  6  7  8  9  10  11  12  13  14\n0      109  34  0  0  0  0  0  0  0  0   0   0   0   0   9\n1      118  37  0  0  0  0  0  0  0  0   0   0   0   0   9\n2       98  36  0  0  0  0  0  0  0  0   0   0   1   0   2\n3       92  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n4       75  37  0  0  0  0  0  0  0  0   0   0   0   0   9\n...    ...  .. .. .. .. .. .. .. .. ..  ..  ..  ..  ..  ..\n30693   83  37  0  0  0  0  0  0  0  0   0   0   0   0   1\n30694   84  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n30695   19  36  0  0  0  0  0  0  0  0   0   0   0   0   8\n30696   74  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n30697   60  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n\n[30698 rows x 15 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bc1f25c332ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m   2580\u001b[0m     \u001b[1;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2581\u001b[0m     \u001b[1;31m# structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2582\u001b[1;33m     \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_input_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2584\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[1;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     raise ValueError(\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: inputs=         0   1  2  3  4  5  6  7  8  9  10  11  12  13  14\n0      109  34  0  0  0  0  0  0  0  0   0   0   0   0   9\n1      118  37  0  0  0  0  0  0  0  0   0   0   0   0   9\n2       98  36  0  0  0  0  0  0  0  0   0   0   1   0   2\n3       92  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n4       75  37  0  0  0  0  0  0  0  0   0   0   0   0   9\n...    ...  .. .. .. .. .. .. .. .. ..  ..  ..  ..  ..  ..\n30693   83  37  0  0  0  0  0  0  0  0   0   0   0   0   1\n30694   84  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n30695   19  36  0  0  0  0  0  0  0  0   0   0   0   0   8\n30696   74  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n30697   60  36  0  0  0  0  0  0  0  0   0   0   0   0   9\n\n[30698 rows x 15 columns]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
