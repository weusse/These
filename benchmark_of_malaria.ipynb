{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p=pd.read_excel('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\all_data_original_english.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling as pp\n",
    "#pp.ProfileReport(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\palu0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palu=pd.read_excel('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\code_these-master\\\\palu0001.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paluu=pd.DataFrame(palu, columns = ['PPOIDS', 'TEMPERATURE', 'S_M8_APPETIT', 'S_FATIGUE', 'S_ARTHRALGI',\n",
    "                                    'S_T_DIGESTIF', 'S_VERTIGE', 'S_FRISSON', 'S_MYALGIE', 'S_DABDO', \n",
    "                                    'S_VOMISS', 'S_NAUSEE', 'S_CEPHALE', 'S_FIEVRE','TDR'])\n",
    "\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "X = paluu\n",
    "y = palu['Diagnostic']\n",
    "X1_train, MX_test, y1_train, My_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#Suréchantillonnage avec l'algorithme SMOTE\n",
    "X1 = paluu\n",
    "y1 =palu['Diagnostic']\n",
    "y1= pd.DataFrame(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas_profiling as pp\n",
    "#pp.ProfileReport(palu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "Re= SMOTE(random_state=0)\n",
    "#X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=0)\n",
    "columns = X1_train.columns\n",
    "Re_data_X1,Re_data_y1=Re.fit_sample(X1_train, y1_train)\n",
    "Re_data_X1 = pd.DataFrame(data=Re_data_X1 ,columns= columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=Re_data_y1, data=Re_data_X1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nous séparons notre jeu données palu en deux parties. Une partie pour entrainer X_train et un partie pour tester X_test\n",
    "# Nous séparons notre variable cible en deux parties. Une partie pour entrainer y_train et une partie pour tester y_test\n",
    "X_train =Re_data_X1\n",
    "y_train=Re_data_y1\n",
    "#y_train= pd.DataFrame(Re_data_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVES BAYES ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary packages   \n",
    "from sklearn.naive_bayes import GaussianNB   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= NB.predict(MX_test)  \n",
    "y_pred=pd.DataFrame(y_pred)\n",
    "print(\"Accuracy NB: {:.2f}\".format(NB.score(y_pred, My_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(My_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {0: \"Not_malaria\", 1: \"Malaria\"}\n",
    "for label in [0, 1]:\n",
    "    print(\"# Results for class {} #\".format(dict_labels[label]))\n",
    "    precision = cm[label, label] / cm[:,label].sum()\n",
    "    recall = cm[label, label] / cm[label, :].sum()\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"precision={}\\nrecall={}\\nf1_score={}\\n\".format(\n",
    "        round(precision, 3), round(recall, 3), round(f1_score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_report\n",
    "print(classification_report(My_test, y_pred,\n",
    "                            target_names=[\"Not_malaria\", \"Malaria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(My_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, NB.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Naive  Bayes(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = list(range(1, 20))\n",
    "max_depth_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to try for max_depth: Tuning the Depth of a Tree\n",
    "# Finding the optimal value formax_depth is one way way to tune your model.\n",
    "# The code below outputs the accuracy for decision trees with different values for max_depth.\n",
    "from sklearn import metrics\n",
    "max_depth_range = list(range(1, 20))# List to store the average RMSE for each value of max_depth:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracy = []\n",
    "for depth in max_depth_range:\n",
    "    clf = DecisionTreeClassifier(max_depth = depth,   random_state = 0)\n",
    "    clf.fit(X_train, y_train) \n",
    "    y_pred1=clf.predict(MX_test)\n",
    "    score = metrics.accuracy_score(My_test, y_pred1)\n",
    "    accuracy.append(score)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to keep in mind that max_depth is not the same thing as depth of a decision tree. max_depth is a way to preprune a decision tree. In other words, if a tree is already as pure as possible at a depth, it will not continue to split. The image below shows decision trees with max_depth values of 3, 4, and 5. Notice that the trees with a max_depth of 4 and 5 are identical. They both have a depth of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict for 1 observation\n",
    "y_pred1=clf.predict(MX_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yd_pred= clf.predict(MX_test) \n",
    "cm_d = confusion_matrix(My_test, yd_pred)\n",
    "cm_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(My_test, y_pred,\n",
    "                            target_names=[\"Not_malaria\", \"Malaria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, clf.predict(MX_test))\n",
    "fpr, tpr, thresholds = roc_curve(My_test, clf.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Decision tree(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "palu_classifier = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000)\n",
    "palu_classifier.fit(X_train, y_train)\n",
    "palu_pred = palu_classifier.predict(MX_test)\n",
    "palu_pred=pd.DataFrame(palu_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.ticker import NullFormatter  # useful for `logit` scale\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "#plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "#sns.set(style=\"white\")\n",
    "#sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "# plot with various axes scales\n",
    "plt.figure(figsize=[8,4],dpi=700)\n",
    "\n",
    "# linear\n",
    "#plt.subplot(111)\n",
    "logit_roc_auc = roc_auc_score(My_test, palu_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, palu_classifier.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='logistic regression(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, clf.predict(MX_test))\n",
    "fpr, tpr, thresholds = roc_curve(My_test, clf.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='Decision tree(area = %0.2f)' % logit_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forests Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forests Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_pred2=rf.predict(MX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(My_test, y_pred2,\n",
    "                            target_names=[\"Not_malaria\", \"Malaria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, y_pred2)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, rf.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Random Forest(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "palu_classifier = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000)\n",
    "palu_classifier.fit(X_train, y_train)\n",
    "palu_pred = palu_classifier.predict(MX_test)\n",
    "palu_pred=pd.DataFrame(palu_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palu_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, palu_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(My_test, palu_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(My_test, palu_pred,\n",
    "                            target_names=[\"Not_malaria\", \"Malaria\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, palu_pred)\n",
    "pred= palu_classifier.predict_proba(MX_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(My_test,pred)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='logistic regression(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM avec kernel=gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier = SVC(kernel='rbf', gamma='auto',probability=True)   \n",
    "svclassifier1 = SVC(kernel='linear', gamma='auto',probability=True) \n",
    "svclassifier2 = SVC(kernel='sigmoid', gamma='auto',probability=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svclassifier = SVC(kernel='rbf', gamma='auto',probability=True)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(MX_test)  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, y_pred))\n",
    "print(confusion_matrix(My_test, y_pred))  \n",
    "print(classification_report(My_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, svclassifier.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='svm gaussian(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM avec kernel=polynom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier1 = SVC(kernel='linear', gamma='auto',probability=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "svclassifier1.fit(X_train, y_train)  \n",
    "y_pred1 = svclassifier1.predict(MX_test)  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, y_pred1))\n",
    "print(confusion_matrix(My_test, y_pred1))  \n",
    "print(classification_report(My_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, y_pred1)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, svclassifier1.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='svm polynom(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM avec kernel=sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svclassifier2 = SVC(kernel='sigmoid', gamma='auto',probability=True)  \n",
    "svclassifier2.fit(X_train, y_train)  \n",
    "y_pred2 = svclassifier2.predict(MX_test)  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, y_pred2))\n",
    "print(confusion_matrix(My_test, y_pred2))  \n",
    "print(classification_report(My_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(My_test, y_pred2)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, svclassifier2.predict_proba(MX_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='svm sigmoid(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,15,15),max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ranomd\n",
    "random.seed(1000)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X1_train = scaler.transform(X_train)\n",
    "X1_test = scaler.transform(MX_test)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,15,15),max_iter=10000)\n",
    "mlp.fit(X1_train,y_train)\n",
    "predictions = mlp.predict(X1_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(My_test, predictions))\n",
    "print(confusion_matrix(My_test,predictions))\n",
    "print(classification_report(My_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(My_test, predictions)\n",
    "fpr, tpr, thresholds = roc_curve(My_test,mlp.predict_proba(X1_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ANN(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.ticker import NullFormatter  # useful for `logit` scale\n",
    "\n",
    "\n",
    "# plot with various axes scales\n",
    "plt.figure(figsize=[8,4],dpi=700)\n",
    "\n",
    "# linear\n",
    "#plt.subplot(111)\n",
    "logit_roc_auc = roc_auc_score(My_test, palu_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, palu_classifier.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='logistic regression(area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, clf.predict(MX_test))\n",
    "fpr, tpr, thresholds = roc_curve(My_test, clf.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='Decision tree(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, y_pred2)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, rf.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='Random Forest(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test,y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, NB.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='Naive  Bayes(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, y_pred1)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, svclassifier1.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='svm polynom(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(My_test, svclassifier.predict_proba(MX_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='svm gaussian(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(My_test, predictions)\n",
    "fpr, tpr, thresholds = roc_curve(My_test,mlp.predict_proba(X_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='ANN(area = %0.2f)' % logit_roc_auc)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('C:\\\\Users\\\\ASUS\\\\Documents\\\\these\\\\articles\\\\article\\\\ROCmg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
